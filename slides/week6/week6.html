<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Week 6</title>
<meta name="author" content="(Sahit Chintalapudi, Jason Gibson)"/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="https://robojackets.github.io/reveal.js/css/reveal.css"/>

<link rel="stylesheet" href="https://robojackets.github.io/reveal.js/css/theme/white.css" id="theme"/>


<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = 'https://robojackets.github.io/reveal.js/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide"><h1 class="title">Week 6</h1>
</section>

<section id="slide-orga374341">
<h2 id="orga374341">What are we doing today</h2>
<ul>
<li>What is Controls?</li>
<li>The Ideal PID Equation</li>
<li>How do we make this work in practice</li>
<li>Walkthrough of the current controls code</li>
<li>Advice on Tuning</li>
<li>Cameras</li>
<li>OpenCV</li>

</ul>
</section>
<section id="slide-org0451daf">
<h2 id="org0451daf">Control Theory</h2>
<ul>
<li>How do we reliably get from point A (our current state) to point B (our
desired state)?</li>
<li>We call the difference between desired and current state at a given time
<span class="underline">error</span></li>
<li>The desired state is also referred to as the <span class="underline">setpoint</span></li>

</ul>
</section>
<section id="slide-org8794c4c">
<h3 id="org8794c4c">Closed Loop Controls</h3>
<ul>
<li>The output of our motor, referred to as its <b>effort</b> is what we have
control over.  Effort is typically something measured as a PWM signal</li>
<li>We get feedback on the state of the robot from sensors. For example, an
encoder gives us ticks/second or an accelerometer would tell us g-forces.
These tell us the <i>state</i> of the robot.</li>
<li>We want to inform the effort of the motor based on the measured robot
state.</li>

</ul>
</section>
<section id="slide-orga0c1e38">
<h3 id="orga0c1e38">Why do we need to study this?</h3>
<ul>
<li>Our robot will be operating in a variety of conditions
<ul>
<li>Differences in battery voltage or driving surface means that the same
motor effort can result in different speeds. We need to account for this</li>
<li>We want our robots motion to be accurate and consistent despite changing
conditions.</li>

</ul></li>
<li>We want our robot's behavior to be "smooth".</li>

</ul>
</section>
<section id="slide-org685473e">
<h3 id="org685473e">A Simple Example: bang-bang controller</h3>
<div class="org-src-container">

<pre  class="src src-C++">effort &lt;- Fixed Output
threshold &lt;- Margin of Error
setpoint &lt;- desired state
<span style="color: #598249;">while</span>(<span style="color: #15968D;">true</span>) {
      <span style="color: #598249;">if</span> (current_state &lt; setpoint - threshold) {
            output(effort);
      } <span style="color: #598249;">else</span> <span style="color: #598249;">if</span> (current_state &gt; setpoint + threshold) {
            output(-effort);
      } <span style="color: #598249;">else</span> {
            output(0);
      }
      update_current_state();
}
</pre>
</div>
<aside class="notes">
<p>
Pros:
      Gets us more or less to our setpoint
      Can account for changing conditions
Cons:
      Bumpy rides ahead (not differentiable)
</p>

</aside>

</section>
<section id="slide-org76f650f">
<h2 id="org76f650f">The PID Controller</h2>
<ul>
<li>Let's vary our motor effort so that the robot's motion isn't as jerky</li>
<li>We're going to build a black box that takes a function of error over time
and spits out motor effort</li>
<li>More specifically:</li>

</ul>

<div class="figure">
<p><img src="https://www.researchgate.net/profile/Vishnu_Divakar/publication/281746636/figure/fig4/AS:284649973665803@1444877250888/Figure-5-PID-Equation.png" alt="Figure-5-PID-Equation.png" />
</p>
</div>
</section>
<section id="slide-orgf00d779">
<h3 id="orgf00d779">The Proportional Component</h3>
<ul>
<li>As we get closer to the setpoint, slow down!</li>
<li>The rate at which we slow down is given by Kp</li>
<li>This is good because we don't see the same boucing back and forth as
bang-bang</li>
<li>This is bad because we'll never quite hit our setpoint (SP).</li>

</ul>
<aside class="notes">
<p>
The problem with just a P controller is called steady state error
The problem isn't as bad with a threshold
</p>

</aside>
</section>
<section id="slide-orgeb89219">
<h3 id="orgeb89219">The Integral Component</h3>
<ul>
<li>Very low error for a long period of time</li>
<li>Add up previous errors and produce an output proportional to that sum</li>
<li>Pro: We now reach our setpoint!</li>
<li>Con: An I gain that's too high will lead to oscillation about the setpoint</li>

</ul>
<aside class="notes">
<p>
This and the D component will have to get sketched up on a whiteboard
Note that the summing we are doing here is basically LRAM
</p>

</aside>
</section>
<section id="slide-orgebec2e6">
<h3 id="orgebec2e6">The Derivative Component</h3>
<ul>
<li>Rather than carrying about the error itself, try to keep the rate at which
the error is changing stable</li>
<li>This helps keep the PID controller smooth</li>
<li>It can also help offset some of the oscillation seen from the I component</li>

</ul>

</section>
<section id="slide-org6e58c0d">
<h2 id="org6e58c0d">Making this work in practice</h2>
<ul>
<li>We can define our state in terms of speed or distance travelled, but speed
makes more sense.</li>
<li>In the I component don't sum over all the old values, just the most recent
ones.</li>
<li>Rather than having your motor effort being output by this PID Controller,
have the PID Controller dictate the change in motor effort.</li>
<li>Often, just a PD controller does the trick</li>

</ul>
<aside class="notes">
<p>
If you have a wide enough margin for error - i.e steering angle - just a P
controller can cut it
</p>

</aside>

</section>
<section id="slide-org7833059">
<h2 id="org7833059">How do we do it right now?</h2>
<ul>
<li><a href="https://github.com/robojackets/roboracing-firmware">https://github.com/robojackets/roboracing-firmware</a></li>

</ul>

</section>
<section id="slide-org87124d1">
<h2 id="org87124d1">Some advice on tuning</h2>
<aside class="notes">
<p>
This is more of an art than a science. Take them through rqt<sub>plot</sub>
</p>

</aside>
<ul>
<li>When starting, set I&amp;D to 0 and just increment P until you're happy with
the behavior</li>
<li>You shouldn't have to recompile/redeploy software everytime you want to
tweak these gains. Launchfile paramaters are your friends!</li>
<li>Rqt (specifically rqt<sub>plot</sub>) is a really useful tool to look at how your
error is changing</li>

</ul>

<aside class="notes">
<p>
Things I wish I could cover but it wouldnt be realistic: (writing these down
in case we do advanced spring sessions)
Motion Profiling (not enough time)
Gain Scheduling (not enough time)
LQR (Wut. How even)
Making our "current<sub>state</sub>" estimate more realistic via Kalman Filters or
something of that nature. (out of scope + not enough time)
</p>

</aside>
</section>
<section id="slide-org2ad6894">
<h2 id="org2ad6894">Cameras</h2>
<ul>
<li>An image is a collection of pixels</li>

</ul>
</section>
<section id="slide-org327228c">
<h3 id="org327228c">Stereo</h3>
<ul>
<li>Can calculate the distances to things
<ul>
<li>Finds the same features on the frames</li>
<li>known distance in between cameras</li>

</ul></li>
<li>Sensitive to amount of features</li>

</ul>

<div class="figure">
<p><img src="https://i2.wp.com/scorpion.tordivel.no/images/3D-Lens-Calculator-Sketch.png" alt="3D-Lens-Calculator-Sketch.png" />
</p>
</div>
</section>
<section id="slide-orgaa46199">
<h2 id="orgaa46199">Computer Vision</h2>
<ul>
<li>We have the knowledge in C++ to describe the logic we might want a robot to
have. But we need to be able to make sense of what the robot sees and
classify it before we can act on this logic.</li>
<li>Cue OpenCV, an open source computer vision library with bindings for C++
(and a few other languages)</li>
<li>I guess our ability to see has been ++'d</li>

</ul>

</section>
<section id="slide-orgd26fe57">
<h2 id="orgd26fe57">OpenCV</h2>
<ul>
<li>Industrial standard for image processing</li>

</ul>

<div class="figure">
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/OpenCV_Logo_with_text_svg_version.svg/1200px-OpenCV_Logo_with_text_svg_version.svg.png" alt="1200px-OpenCV_Logo_with_text_svg_version.svg.png" width="30%" />
</p>
</div>
</section>
<section id="slide-orga7d4066">
<h2 id="orga7d4066">What does an Image look like to your computer?</h2>
<ul>
<li>OpenCV stores images in an object called a <i>Mat</i></li>
<li>A Mat is an array with rows and columns. Each element
of the Mat is a pixel in the image and its location in the Mat corresponds
to its location in the image</li>
<li>Computers have no concept of "2d", so Images in memory are <i>continuous</i>.
This means each row of the image is appended onto the end of the last. To
iterate through a Mat you just get a pointer to the beginning of the first
row and keep track of your row number by how far you've traversed.</li>

</ul>
</section>
<section id="slide-orgdc97e02">
<h2 id="orgdc97e02">Color Types</h2>
<ul>
<li>There are many different formats for an image
<ul>
<li>Grey scale</li>
<li>RGB</li>
<li>HSV</li>

</ul></li>

</ul>
</section>
<section id="slide-org629325e">
<h3 id="org629325e">Grey scale</h3>
<ul>
<li>An image where each pixel is only white to black</li>
<li>Range [0-255]
<ul>
<li>255 is white</li>
<li>0 is black</li>

</ul></li>

</ul>
</section>
<section id="slide-orge0e9fa7">
<h3 id="orge0e9fa7">Color Images</h3>
<ul>
<li>Color images don't embed the color of a pixel in one element. Often, you'll
find each pixel represented in BGR (Blue component, Green Component, Red
Component) form. So now, each row of a color image is 3 times as long as a
row of a black and white image.</li>
<li><img src="https://i.imgur.com/QlokNTv.png" alt="QlokNTv.png" /></li>
<li>Images don't have to be stored in just BGR format!</li>

</ul>

</section>
<section id="slide-orgd90a257">
<h3 id="orgd90a257">HSV Images</h3>
<ul>
<li>Each Pixel in a color image has a hue, a saturation, and a luminosity.</li>
<li>Even though our cameras read in images with RGB, converting them to HSV is
easy with OpenCV</li>

</ul>

<div class="figure">
<p><img src="https://image.slidesharecdn.com/01presentationhuehistograms-150707215651-lva1-app6892/95/about-perception-and-hue-histograms-in-hsv-space-5-638.jpg" alt="about-perception-and-hue-histograms-in-hsv-space-5-638.jpg" />
</p>
</div>
</section>
<section id="slide-orgf07956c">
<h4 id="orgf07956c">HSV explained</h4>
<ul>
<li>Hue
<ul>
<li>The actual color</li>

</ul></li>
<li>Saturation
<ul>
<li>Indicates the amount of grey</li>

</ul></li>
<li>Luminosity
<ul>
<li>How dark the color is</li>

</ul></li>

</ul>

<div class="figure">
<p><img src="https://www.nmt.edu/tcc/help/pubs/colortheory/img/cone.png" alt="cone.png" width="30%" />
</p>
</div>

</section>
<section id="slide-orgf0c64e9">
<h4 id="orgf0c64e9">Why do we use HSV</h4>
<ul>
<li>HSV encodes image data in a way that is resistant to changes in color</li>
<li>To put it another way, on a sunny day an image will contain more red, more
blue, and more green than on a cloudy day. All three channels are affected.</li>
<li>On a sunny day, the saturation channel will be largely effected, but we can
expect hue to remain mainly stable. This makes it easier to do searches for
colors in the HSV space.</li>

</ul>

</section>
<section id="slide-org4053e52">
<h2 id="org4053e52">Finding the blue in an image</h2>
<p>
<a href="https://github.com/RoboJackets/ros-training/blob/master/code/week6/src/findBlue.cpp">https://github.com/RoboJackets/ros-training/blob/master/code/week6/src/findBlue.cpp</a>
</p>

</section>
<section id="slide-org4a7a24f">
<h2 id="org4a7a24f">Roboracing Computer Vision</h2>
<p>
<a href="https://github.com/RoboJackets/roboracing-software/blob/master/iarrc/src/color_detector/color_detector.cpp">Roboracing
Color Detector</a>
</p>
</section>
<section id="slide-org20efd30">
<h2 id="org20efd30">What would make this training better?</h2>
</section>
</section>
</div>
</div>
<script src="https://robojackets.github.io/reveal.js/lib/js/head.min.js"></script>
<script src="https://robojackets.github.io/reveal.js/js/reveal.js"></script>

<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({

controls: false,
progress: true,
history: false,
center: true,
slideNumber: 'c',
rollingLinks: false,
keyboard: true,
overview: true,
width: 1440,
height: 800,
margin: 0.15,

theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
transition: Reveal.getQueryHash().transition || 'linear', // default/cube/page/concave/zoom/linear/fade/none
transitionSpeed: 'fast',
multiplex: {
    secret: '', // null if client
    id: '', // id, obtained from socket.io server
    url: '' // Location of socket.io server
},

// Optional libraries used to extend on reveal.js
dependencies: [
 { src: 'https://robojackets.github.io/reveal.js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
]
});
</script>
</body>
</html>
